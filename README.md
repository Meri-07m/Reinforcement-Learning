# Reinforcement-Learning

This repository contains **10 Reinforcement Learning (RL)** projects, each demonstrating the application of different RL algorithms to solve various problems and environments. These projects are designed to provide hands-on learning and exploration of various RL techniques, including **Q-learning**, **SARSA**, **Monte Carlo**, and more.

## Projects in This Repository

### 1. [Blackjack](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/blackjack)
   - **Description**: A Blackjack game environment where RL algorithms are used to train an agent to play optimally.
   - **Algorithms used**: SARSA, Q-learning, Monte Carlo Methods.
   - **Objective**: Maximize rewards by learning an optimal strategy to beat the dealer.

### 2. [Cliff Walking](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/cliff-walking)
   - **Description**: A Gridworld problem where the agent needs to avoid cliffs and reach a goal.
   - **Algorithms used**: SARSA, Q-learning.
   - **Objective**: Navigate through the grid while avoiding dangerous cliffs to maximize cumulative rewards.

### 3. [Windy Gridworld](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/windy-gridworld)
   - **Description**: A variation of the gridworld environment where wind forces affect the agentâ€™s movement, making navigation more challenging.
   - **Algorithms used**: SARSA, Q-learning.
   - **Objective**: Reach the goal in the grid while learning to navigate the wind's impact on movement.

### 4. [Ten-Armed Testbed](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/ten-armed-testbed)
   - **Description**: The Ten-Armed Bandit problem is used to test RL algorithms for balancing exploration vs exploitation.
   - **Algorithms used**: Îµ-greedy, UCB (Upper Confidence Bound), Gradient Bandit.
   - **Objective**: Maximize the cumulative reward by selecting the optimal arm in a slot machine-like environment.

### 5. [Random Walk](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/random-walk)
   - **Description**: A simple random walk problem that demonstrates learning in a probabilistic environment.
   - **Algorithms used**: Monte Carlo Methods, Temporal Difference Learning.
   - **Objective**: Learn the optimal actions to maximize rewards over time in a stochastic setting.

### 6. [Infinite Variance](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/infinite-variance)
   - **Description**: An environment with infinite variance rewards to demonstrate how RL agents adapt to highly variable environments.
   - **Algorithms used**: Monte Carlo, Q-learning, SARSA.
   - **Objective**: Learn effective strategies in environments with high variance and unpredictable rewards.

### 7. [Gridworld MDP](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/gridworld-mdp)
   - **Description**: A Markov Decision Process (MDP) where an agent must navigate a gridworld to reach a goal.
   - **Algorithms used**: Value Iteration, Policy Iteration.
   - **Objective**: Learn the optimal policy using dynamic programming methods to maximize cumulative rewards.

### 8. [Gamblerâ€™s Problem](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/gambler-problem)
   - **Description**: A classic problem where the agent needs to maximize its wealth over a series of gambles.
   - **Algorithms used**: Dynamic Programming, Value Iteration.
   - **Objective**: Maximize the agent's wealth over a set of gambles by determining optimal betting strategies.

### 9. [Blackjack with Deep Q-Learning](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/blackjack-dqn)
   - **Description**: Extension of the Blackjack project where a **Deep Q-Network (DQN)** is used to solve the Blackjack problem.
   - **Algorithms used**: Deep Q-Learning.
   - **Objective**: Apply deep reinforcement learning to learn an optimal strategy for Blackjack.

### 10. [Multi-Armed Bandit with Contextual Information](https://github.com/Meri-07m/Reinforcement-Learning/tree/main/contextual-bandit)
   - **Description**: A variant of the Multi-Armed Bandit problem, where arms have additional contextual information that can influence their rewards.
   - **Algorithms used**: Contextual Bandit, UCB (Upper Confidence Bound).
   - **Objective**: Learn the optimal arms to pull based on contextual data.

## ðŸ¤– Algorithms Implemented

This repository showcases several **Reinforcement Learning (RL)** algorithms, including:

- **Q-Learning**
- **SARSA (State-Action-Reward-State-Action)**
- **Monte Carlo Methods**
- **Temporal Difference Learning**
- **Value Iteration**
- **Policy Iteration**
- **Îµ-greedy**
- **Upper Confidence Bound (UCB)**
- **Gradient Bandit**

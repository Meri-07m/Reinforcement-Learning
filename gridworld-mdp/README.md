# ðŸ§­ Gridworld as a Markov Decision Process (MDP)

This project implements the **Gridworld** environment as a classic **Markov Decision Process (MDP)**, used to demonstrate core reinforcement learning concepts such as dynamic programming, policy evaluation, and value iteration.

## ðŸ“Œ Overview

The Gridworld environment consists of a 2D grid where an agent moves in four directions: up, down, left, and right. Each move yields a reward, and the agent's objective is to learn an optimal policy to maximize cumulative reward.

This setup is commonly used to study:

- Policy Evaluation
- Policy Iteration
- Value Iteration
- Bellman Equations

## ðŸ§  Concepts Demonstrated

- Finite MDP modeling
- State-value and action-value functions
- Dynamic Programming techniques
- Convergence of policies and value functions
- Visualization of optimal paths and policies

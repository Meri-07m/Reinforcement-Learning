# ðŸ§­ Gridworld with Dynamic Programming

This project implements **Dynamic Programming (DP)** algorithmsâ€”specifically **Policy Iteration** and **Value Iteration**â€”to solve a **Gridworld** environment modeled as a **Markov Decision Process (MDP)**.

## ðŸ“Œ Overview

Gridworld is a classic reinforcement learning environment where an agent navigates a grid to reach a goal while avoiding obstacles. The agent's objective is to learn an optimal policy that maximizes cumulative reward.

This project demonstrates:

- **Policy Evaluation**: Estimating the value function for a given policy.
- **Policy Improvement**: Updating the policy based on the value function.
- **Value Iteration**: Iteratively improving the value function and policy.

## ðŸ§  Key Concepts

- **MDP Components**: States, actions, rewards, and transitions.
- **Discount Factor (Î³)**: Determines the importance of future rewards.
- **Convergence**: Both Policy Iteration and Value Iteration converge to the optimal policy and value function.

---

# üß≠ Gridworld with Dynamic Programming

This project implements **Dynamic Programming (DP)** algorithms‚Äîspecifically **Policy Iteration** and **Value Iteration**‚Äîto solve a **Gridworld** environment modeled as a **Markov Decision Process (MDP)**.

## üìå Overview

Gridworld is a classic reinforcement learning environment where an agent navigates a grid to reach a goal while avoiding obstacles. The agent's objective is to learn an optimal policy that maximizes cumulative reward.

This project demonstrates:

- **Policy Evaluation**: Estimating the value function for a given policy.
- **Policy Improvement**: Updating the policy based on the value function.
- **Value Iteration**: Iteratively improving the value function and policy.

## üß† Key Concepts

- **MDP Components**: States, actions, rewards, and transitions.
- **Discount Factor (Œ≥)**: Determines the importance of future rewards.
- **Convergence**: Both Policy Iteration and Value Iteration converge to the optimal policy and value function.

## üìÅ Project Structure
